{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "############ OLD! use version from registration.py #############\n",
    "# first try, 2d affine test\n",
    "\n",
    "# TODO: use version from registration.py -> make package\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# first try, 2d affine test\n",
    "\n",
    "from registration import *\n",
    "\n",
    "\n",
    "\n",
    "make_coeff_affine2d_fixed(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some rotated points\n",
    "\n",
    "a = np.pi / 16\n",
    "a2 = np.pi / 12\n",
    "rot = np.array([[np.cos(a), -np.sin(a)],[np.sin(a), np.cos(a)]])\n",
    "rot2 = np.array([[np.cos(a2), -np.sin(a2)],[np.sin(a2), np.cos(a2)]])\n",
    "p1 = [np.random.uniform(size=2) for _ in range(32)]\n",
    "p2 = [rot.dot(p) for p in p1]\n",
    "p3 = [rot2.dot(p) for p in p2]\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot([p[0] for p in p1], [p[1] for p in p1], '.')\n",
    "plt.plot([p[0] for p in p2], [p[1] for p in p2], '.')\n",
    "plt.plot([p[0] for p in p3], [p[1] for p in p3], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = []\n",
    "ys = []\n",
    "\n",
    "for (xf, x) in zip(p1, p2):\n",
    "    c, y = make_coeffs_affine_nd_fixed(xf, x, 2, 0, 2)\n",
    "    coeffs.append(c)\n",
    "    ys.append(y)\n",
    "\n",
    "for (x1, x2) in zip(p2, p3):\n",
    "    c, y = make_coeffs_affine_nd(x1, x2, 2, 0, 1, 2)\n",
    "    coeffs.append(c)\n",
    "    ys.append(y)\n",
    "\n",
    "\n",
    "coeffs = np.vstack(coeffs)\n",
    "ys = np.concatenate(ys)\n",
    "\n",
    "r, _, _, _ = np.linalg.lstsq(coeffs, ys, rcond=None)\n",
    "\n",
    "rot\n",
    "\n",
    "print(r[6:].reshape((2,3)))\n",
    "print(np.linalg.inv(rot2.dot(rot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr1 = np.array([12,124.2])\n",
    "tr2 = np.array([-1,14.2])\n",
    "p1 = [np.random.uniform(size=2) for _ in range(50000)]\n",
    "p2 = [p + tr1 for p in p1]\n",
    "p3 = [p + tr2 + np.random.uniform(-2,2,2) for p in p2]\n",
    "\n",
    "coeffs = []\n",
    "ys = []\n",
    "\n",
    "for (xf, x) in zip(p1, p2):\n",
    "    c, y = make_coeffs_translation_nd(xf, x, 2, 0, 1, 3)\n",
    "    coeffs.append(c)\n",
    "    ys.append(y)\n",
    "\n",
    "for (x1, x2) in zip(p2, p3):\n",
    "    c, y = make_coeffs_translation_nd(x1, x2, 2, 1, 2, 3)\n",
    "    coeffs.append(c)\n",
    "    ys.append(y)\n",
    "\n",
    "\n",
    "coeffs = np.vstack(coeffs)\n",
    "ys = np.concatenate(ys)\n",
    "\n",
    "r, _, _, _ = np.linalg.lstsq(coeffs, ys, rcond=None)\n",
    "\n",
    "rot\n",
    "\n",
    "print(r[4:] - r[:2])\n",
    "print(-(tr2+tr1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from io import BytesIO\n",
    "from sys import stdout\n",
    "from xml.etree.ElementTree import ElementTree, Element, SubElement, dump\n",
    "from xml.dom.minidom import parse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "\n",
    "def add_array_set(l, a, id_a):\n",
    "    \"\"\"\n",
    "    add array to list of arrays, only keep unique\n",
    "    return index of added or kept array\n",
    "    \"\"\"\n",
    "    for id_b, b in enumerate(l):\n",
    "        if np.allclose(a, b):\n",
    "            return id_b\n",
    "    l += [a]\n",
    "    return id_a\n",
    "\n",
    "# collect list of pixel coordinates per pair\n",
    "res = {}\n",
    "\n",
    "# accumulate manual click output from multiple files\n",
    "content = ''\n",
    "files = (\n",
    "    '/Volumes/davidh-ssd/manual_ips_angle1_v1.txt',\n",
    "    '/Volumes/davidh-ssd/manual_ips_angle2.txt',\n",
    "    '/Volumes/davidh-ssd/manual_ips_mview.txt',\n",
    ")\n",
    "for file in files:\n",
    "    with open(file, 'r') as fd:\n",
    "        content += '\\n' + fd.read()\n",
    "\n",
    "# split on pair header : !vid_a-vid_b\n",
    "pair_cts = content.split('\\n!')\n",
    "p_header = re.compile('!*([0-9]+)-([0-9]+)')\n",
    "\n",
    "for pair_ct in pair_cts:\n",
    "\n",
    "    # ignore empty or commented-out content\n",
    "    if pair_ct.strip() == '' or pair_ct.strip().startswith('#'):\n",
    "        continue\n",
    "    \n",
    "    # get vid-pair\n",
    "    header = pair_ct.strip().split('\\n', 1)[0]\n",
    "    vid_a, vid_b = p_header.match(header.strip()).groups()\n",
    "    \n",
    "    res_pair = []\n",
    "    pa = re.compile('.*?tpId=0 setupId={}--- global: (\\(.*?\\))--- pixel: (\\(.*?\\)).*?'.format(vid_a))\n",
    "    pb = re.compile('.*?\\n?tpId=0 setupId={}--- global: (\\(.*?\\))--- pixel: (\\(.*?\\)).*?'.format(vid_b))\n",
    "    \n",
    "    # split on --- lines\n",
    "    lines = pair_ct.split('---\\n')[1:]\n",
    "    \n",
    "    # go over pairs of file chunks\n",
    "    for line_a, line_b in zip(*[iter(lines)]*2):\n",
    "        \n",
    "        try:\n",
    "            # parse global, pixel coords\n",
    "            gla, pxa = pa.match(line_a.strip()).groups()\n",
    "            glb, pxb = pb.match(line_b.strip()).groups()\n",
    "        except AttributeError as ex:\n",
    "            print('Error parsing {} on:\\n{}\\n{}'.format((vid_a, vid_b), line_a, line_b))\n",
    "            continue\n",
    "            \n",
    "        # add as pair of np-arrays\n",
    "        res_pair += [(np.array([*map(float, pxa.strip('()').split(','))]),\n",
    "                      np.array([*map(float, pxb.strip('()').split(','))]))]\n",
    "    \n",
    "    # add all for pair\n",
    "    res[(int(vid_a), int(vid_b))] = res_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for outlier removal\n",
    "# roughly based on http://docs.pointclouds.org/1.7.1/classpcl_1_1_statistical_outlier_removal.html#details\n",
    "sd_mult_t = 3.0 # how many sds pixel-click pairs may devate from mean until they are removed\n",
    "p_estim = 0.8 # quantile of pixel-click pairs to use for mean, sd estimation\n",
    "\n",
    "# format string for MVR interest point files \n",
    "ip_fstring = '/Volumes/davidh-ssd/BS_TEST/interestpoints/tpId_0_viewSetupId_{}.beads.ip.txt'\n",
    "\n",
    "res_ip = {}\n",
    "for vid_a, vid_b in res.keys():\n",
    "\n",
    "    # build kdtrees for real ips\n",
    "    df_a = pd.read_csv(ip_fstring.format(vid_a), sep='\\t')\n",
    "    locs_a = np.array(df_a[['x', 'y', 'z']])\n",
    "    kd_a = KDTree(locs_a)\n",
    "    df_b = pd.read_csv(ip_fstring.format(vid_b), sep='\\t')\n",
    "    locs_b = np.array(df_b[['x', 'y', 'z']])\n",
    "    kd_b = KDTree(locs_b)\n",
    "\n",
    "    res_pair = [] # pixel point pairs from IPs\n",
    "    manual_pair = [] # pixel point pairs from clicks\n",
    "    # find closest neighbours\n",
    "    for point_a, point_b in res[(vid_a, vid_b)]:\n",
    "        d_a, idx_a = kd_a.query(point_a)\n",
    "        d_b, idx_b = kd_b.query(point_b)\n",
    "        # keep pair only if we find reasonable match (distance of both < d_thresh)\n",
    "        # NB: removed for statistical outlier removal\n",
    "        #if (d_a < d_thresh and d_b < d_thresh):\n",
    "        res_pair += [(locs_a[idx_a], locs_b[idx_b])]\n",
    "        manual_pair += [(point_a, point_b)]\n",
    "\n",
    "    # filter outliers    \n",
    "    # vid_a: get mean and sd of pixel-clicked coordinates\n",
    "    ds = [l1 - l2 for (l1,_),(l2,_) in zip(res_pair, manual_pair)]\n",
    "    mu, sd = (np.mean(np.array(sorted(ds, key= lambda p: np.linalg.norm(p))[:int(len(ds)*p_estim)]), axis=0),\n",
    "              np.std(np.array(sorted(ds, key= lambda p: np.linalg.norm(p))[:int(len(ds)*p_estim)]), axis=0))\n",
    "    \n",
    "    # remember indices of good points\n",
    "    idxes_good = set([idx for idx, d in enumerate(ds) if np.all(np.abs(mu-d) < sd * sd_mult_t)])\n",
    "\n",
    "    # same for vid_b\n",
    "    ds = [l1 - l2 for (_, l1),(_, l2) in zip(res_pair, manual_pair)]\n",
    "    mu, sd = (np.mean(np.array(sorted(ds, key= lambda p: np.linalg.norm(p))[:int(len(ds)*p_estim)]), axis=0),\n",
    "              np.std(np.array(sorted(ds, key= lambda p: np.linalg.norm(p))[:int(len(ds)*p_estim)]), axis=0))\n",
    "    \n",
    "    # good points for both views\n",
    "    idxes_good &= set([idx for idx, d in enumerate(ds) if np.all(np.abs(mu-d) < sd * sd_mult_t)])\n",
    "    \n",
    "    # keep filtered IP coordinate pairs\n",
    "    res_pair_filt = [rp for idx,rp in enumerate(res_pair) if idx in idxes_good] \n",
    "    res_ip[(vid_a, vid_b)] = res_pair_filt\n",
    "\n",
    "# quick check: how many pairs remain?\n",
    "for k, v in res_ip.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle1_idxs = list(range(6)) + list(range(12,18))\n",
    "res2_rot = {(i1, i2):  list(zip(\n",
    "          [p[0] if i1 in angle1_idxs else p[0] * np.array([-1,1,-1]) for p in v],\n",
    "          [p[1] if i2 in angle1_idxs else p[1] * np.array([-1,1,-1]) for p in v])) for (i1,i2) ,v in res_ip.items()}\n",
    "\n",
    "res_ip2 = {k: ([p[0] for p in v], [p[1] for p in v]) for k,v in res2_rot.items()}\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook\n",
    "reg = register_affine(res_ip2, [0])\n",
    "\n",
    "from collections import defaultdict\n",
    "transformed = defaultdict(list)\n",
    "err = defaultdict(list)\n",
    "for (i1, i2), pairs in res2_rot.items():\n",
    "    for p1, p2 in pairs:\n",
    "        t1 = aug_mat(reg[i1]).dot(aug_vec(p1))[:3]\n",
    "        t2 = aug_mat(reg[i2]).dot(aug_vec(p2))[:3]\n",
    "        transformed[i1].append(t1)\n",
    "        transformed[i2].append(t2)\n",
    "        err[(i1, i2)].append(np.linalg.norm(t1-t2))\n",
    "        \n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for ps in transformed.values():\n",
    "    xs, ys, zs = [], [], []\n",
    "    for d in ps:\n",
    "        xs.append(d[0])\n",
    "        ys.append(d[1])\n",
    "        zs.append(d[2])\n",
    "        ax.scatter(xs, ys, zs, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "for k,v in err.items():\n",
    "    print(k, np.mean(v))\n",
    "    \n",
    "np.mean([np.mean(v) for k,v in err.items()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
